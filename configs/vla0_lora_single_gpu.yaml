# VLA-0 LoRA Training Configuration (single GPU friendly)
# Usage:
#   uv pip install -e ".[lora]"
#   python scripts/train.py --config configs/vla0_lora_single_gpu.yaml

# === ModelArguments ===
model_id: "Qwen/Qwen2.5-VL-3B-Instruct"
use_flash_attention: true
finetune_mode: "lora"
lora_r: 16
lora_alpha: 32
lora_dropout: 0.05

# === DataArguments ===
repo_id: "physical-intelligence/libero"
history: 1
horizon: 8
# Smaller images save a lot of VRAM. Increase if you have headroom.
img_size: 168
crop_ratio: 0.875
# Disable wrist camera to cut vision tokens roughly in half.
use_wrist_image: false
# Multi-cam requires tiling; for single-cam this flag is ignored.
tile_images: true
brightness_aug: 0.2
contrast_aug: 0.2
saturation_aug: 0.2
hue_aug: 0.05

# === VLATrainingArguments ===
action_mask_aug_pct: 0.4

# === SFTConfig (from TRL) ===
output_dir: "./runs/vla0_sft_lora_single_gpu"
num_train_epochs: 1
per_device_train_batch_size: 1
gradient_accumulation_steps: 8
learning_rate: 1.0e-4
lr_scheduler_type: "constant"
weight_decay: 0.0
warmup_steps: 0
logging_steps: 10
save_total_limit: 5
save_steps: 2000
bf16: true
gradient_checkpointing: true
dataloader_num_workers: 4
report_to: ["tensorboard", "wandb"]
seed: 42


